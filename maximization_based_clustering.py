# -*- coding: utf-8 -*-
"""Maximization based clustering

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19AU8M2xmC1EEydXC7sLqQT8hZ549AqVQ
"""

import pandas as pd
import numpy as np
from sklearn.mixture import GaussianMixture

# Load the dataset (replace with your actual data file)
data = pd.read_csv("/content/sample_data/IRIS.csv")

# Select features for clustering (numerical features)
features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']
X = data[features]

# Expectation-Maximization (using Gaussian Mixture Model)
# Determine optimal number of clusters (e.g., using AIC or BIC)
n_components_range = range(1, 10)  # Test different numbers of clusters
lowest_bic = np.inf  # Use np.inf instead of np.infty
optimal_n_components = 0

for n_components in n_components_range:
    gmm = GaussianMixture(n_components=n_components, covariance_type='full', random_state=0)
    gmm.fit(X)
    bic = gmm.bic(X)
    if bic < lowest_bic:
        lowest_bic = bic
        optimal_n_components = n_components

print(f"Optimal number of clusters (based on BIC): {optimal_n_components}")

# Fit the GMM with the optimal number of clusters
gmm = GaussianMixture(n_components=optimal_n_components, covariance_type='full', random_state=0)
gmm.fit(X)

# Predict cluster labels
labels = gmm.predict(X)

# Add cluster labels to the DataFrame
data['cluster_gmm'] = labels

# Print or visualize the results
print(data.head())

# Example visualization (using the first two features)
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
for cluster in range(optimal_n_components):
    cluster_data = data[data['cluster_gmm'] == cluster]
    plt.scatter(cluster_data['sepal_length'], cluster_data['sepal_width'], label=f'Cluster {cluster}')

plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.title('EM Clustering (Gaussian Mixture Model)')
plt.legend()
plt.show()